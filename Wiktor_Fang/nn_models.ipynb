{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path\n",
    "directory_path = './labels_final'\n",
    "# current directory\n",
    "c_dir = os.getcwd()\n",
    "\n",
    "# all actions\n",
    "actions = np.array(sorted([folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))])) # sorted to follow folder arrangement\n",
    "\n",
    "# specific actions\n",
    "# actions = np.array(['alligator', 'flower', 'kiss', 'listen', 'orange'])\n",
    "# actions = np.array(['afternoon', 'house', 'again', 'open', 'kiss', 'sorry'])\n",
    "# actions = np.array(sorted([folder for folder in os.listdir('./labels_new') if os.path.isdir(os.path.join(directory_path, folder))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0,\n",
       " 'base': 1,\n",
       " 'bye': 2,\n",
       " 'close': 3,\n",
       " 'down': 4,\n",
       " 'for': 5,\n",
       " 'good': 6,\n",
       " 'have': 7,\n",
       " 'hello': 8,\n",
       " 'how': 9,\n",
       " 'if': 10,\n",
       " 'listen': 11,\n",
       " 'mad': 12,\n",
       " 'nap': 13,\n",
       " 'no': 14,\n",
       " 'noisy': 15,\n",
       " 'now': 16,\n",
       " 'please': 17,\n",
       " 'quiet': 18,\n",
       " 'sad': 19,\n",
       " 'show': 20,\n",
       " 'thankyou': 21,\n",
       " 'time': 22,\n",
       " 'we': 23,\n",
       " 'will': 24,\n",
       " 'work': 25}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary for int representation of actions\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at this point, we will not access the video folder, only the numpy folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from Preprocessing.mp_support import mediapipe_detection, draw_landmarks, draw_styled_landmarks, extract_keypoints, extract_coordinates, prob_viz\n",
    "\n",
    "class VideoPreprocessing():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.savepath = \"./Pipeline/video\"\n",
    "        self.clean_folder()\n",
    "        pass\n",
    "\n",
    "    def clean_folder(self) -> None:\n",
    "        # Get a list of all files in the folder\n",
    "        files = os.listdir(self.savepath)\n",
    "\n",
    "        # Iterate over the files and remove each one\n",
    "        for file in files:\n",
    "            file_path = os.path.join(self.savepath, file)\n",
    "            os.remove(file_path)\n",
    "\n",
    "    def process_video(self, video_path) -> pd.DataFrame:\n",
    "        self.extract_frames_data(video_path)\n",
    "        return self.convert_to_df()\n",
    "\n",
    "    def extract_frames_data(self, path) -> None:\n",
    "        extract_coordinates(path, self.savepath)\n",
    "\n",
    "    def convert_to_df(self) -> pd.DataFrame:\n",
    "\n",
    "        # create empty data frame\n",
    "        df = pd.DataFrame(columns=['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z'])\n",
    "        \n",
    "        frame_counter = 1 \n",
    "        \n",
    "        # for video\n",
    "        for frame in os.listdir(self.savepath):\n",
    "            \n",
    "            frame_path = os.path.join(self.savepath, frame)\n",
    "            \n",
    "            with open(frame_path, 'rb') as file:\n",
    "                npy_data = np.load(file)\n",
    "            \n",
    "                # scan through npy file and add data to df in batches of 3\n",
    "                local_count = 1\n",
    "                for j in range(0, 99, 3):\n",
    "                    new_row = pd.Series({'frame': frame_counter, 'row_id': f\"{frame_counter}-pose-{local_count}\", 'type': 'pose', 'landmark_index': local_count, 'x': npy_data[j], 'y': npy_data[j+1], 'z': npy_data[j+2]})\n",
    "                    \n",
    "                    df = pd.concat([df, new_row.to_frame().T], ignore_index = True, axis = 0)\n",
    "                    \n",
    "                    local_count += 1\n",
    "                \n",
    "                local_count = 1\n",
    "                for j in range(99, 162, 3):\n",
    "                    new_row = pd.Series({'frame': frame_counter, 'row_id': f\"{frame_counter}-left_hand-{local_count}\", 'type': 'left_hand', 'landmark_index': local_count, 'x': npy_data[j], 'y': npy_data[j+1], 'z': npy_data[j+2]})\n",
    "                    \n",
    "                    df = pd.concat([df, new_row.to_frame().T], ignore_index = True, axis = 0)\n",
    "                    \n",
    "                    local_count += 1\n",
    "                \n",
    "                local_count = 1\n",
    "                for j in range(162, 225, 3):\n",
    "                    new_row = pd.Series({'frame': frame_counter, 'row_id': f\"{frame_counter}-right_hand-{local_count}\", 'type': 'right_hand', 'landmark_index': local_count, 'x': npy_data[j], 'y': npy_data[j+1], 'z': npy_data[j+2]})\n",
    "                    \n",
    "                    df = pd.concat([df, new_row.to_frame().T], ignore_index = True, axis = 0)\n",
    "                    \n",
    "                    local_count += 1\n",
    "                \n",
    "            frame_counter += 1\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"d:\\\\SMU\\\\ml&applns\")\n",
    "\n",
    "from Preprocessing.DFTransformations import *\n",
    "from Preprocessing.DataExtration import *\n",
    "from Preprocessing.Average_parquet import Averager\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "class Pipeline():\n",
    "\n",
    "    def __init__(self, path_to_video) -> None:\n",
    "        self.frames_target = 65\n",
    "        self.duplicate = True\n",
    "        self.remove_points = True\n",
    "\n",
    "        with open('./Preprocessing/standard_scaler.pkl', 'rb') as f:\n",
    "            self.scaler = pickle.load(f)\n",
    "\n",
    "        data = VideoPreprocessing().process_video(path_to_video)\n",
    "        self.data = Averager(data).average_pf()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Pipeline at 0x18513944910>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./Show/Show1.mp4\"\n",
    "Pipeline(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sequences, labels = [], []  # sequence -> video, labels -> action\n",
    "\n",
    "directory_path = \"./Pipeline\"\n",
    "action = \"/video\"\n",
    "action_counter = 0\n",
    "window = []         # window -> single frame\n",
    "no_frames_per_action = len(os.listdir(directory_path+action))\n",
    "if no_frames_per_action >= 15 and no_frames_per_action < 150:\n",
    "    action_counter += 1\n",
    "    for frame_num in range(1, no_frames_per_action + 1):\n",
    "        res = np.load(directory_path + action + f\"/{frame_num}.npy\")    # res -> coordinate key points\n",
    "        window.append(res)\n",
    "    sequences.append(window)\n",
    "    labels.append(25)\n",
    "print('-'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to difference in number of frames, pad x and y\n",
    "# x = np.array(pad_sequences(sequences, dtype = 'float', padding = 'post', value = 0))\n",
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the amount of padding you want for each dimension\n",
    "pad_amount = [(0, 0), (290, 0), (0, 0)]  # Padding amount for each dimension\n",
    "\n",
    "# Pad the array\n",
    "padded_array = np.pad(x, pad_width=pad_amount, mode='constant', constant_values=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 321, 225)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"lstm_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(padded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is460proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
