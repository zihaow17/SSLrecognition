{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path\n",
    "directory_path = './labels'\n",
    "# current directory\n",
    "c_dir = os.getcwd()\n",
    "\n",
    "# all actions\n",
    "actions = np.array(sorted([folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))])) # sorted to follow folder arrangement\n",
    "\n",
    "# specific actions\n",
    "# actions = np.array(['alligator', 'flower', 'kiss', 'listen', 'orange'])\n",
    "# actions = np.array(['afternoon', 'house', 'again', 'open', 'kiss', 'sorry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afternoon': 0,\n",
       " 'again': 1,\n",
       " 'alligator': 2,\n",
       " 'base': 3,\n",
       " 'door': 4,\n",
       " 'flower': 5,\n",
       " 'hello': 6,\n",
       " 'house': 7,\n",
       " 'how': 8,\n",
       " 'kiss': 9,\n",
       " 'listen': 10,\n",
       " 'open': 11,\n",
       " 'orange': 12,\n",
       " 'see': 13,\n",
       " 'sorry': 14,\n",
       " 'why': 15}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary for int representation of actions\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at this point, we will not access the video folder, only the numpy folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/afternoon\n",
      "Number of instances: 40\n",
      "Number of frames in afternoon_1: 31\n",
      "Number of frames in afternoon_2: 30\n",
      "Number of frames in afternoon_3: 30\n",
      "Number of frames in afternoon_4: 30\n",
      "Number of frames in afternoon_5: 31\n",
      "Number of frames in afternoon_6: 31\n",
      "Number of frames in afternoon_7: 31\n",
      "Number of frames in afternoon_8: 30\n",
      "Number of frames in afternoon_9: 31\n",
      "Number of frames in afternoon_10: 31\n",
      "Number of frames in afternoon_11: 31\n",
      "Number of frames in afternoon_12: 31\n",
      "Number of frames in afternoon_13: 31\n",
      "Number of frames in afternoon_14: 31\n",
      "Number of frames in afternoon_15: 31\n",
      "Number of frames in afternoon_16: 31\n",
      "Number of frames in afternoon_17: 31\n",
      "Number of frames in afternoon_18: 31\n",
      "Number of frames in afternoon_19: 31\n",
      "Number of frames in afternoon_20: 31\n",
      "Number of frames in afternoon_21: 31\n",
      "Number of frames in afternoon_22: 31\n",
      "Number of frames in afternoon_23: 31\n",
      "Number of frames in afternoon_24: 31\n",
      "Number of frames in afternoon_25: 31\n",
      "Number of frames in afternoon_26: 31\n",
      "Number of frames in afternoon_27: 30\n",
      "Number of frames in afternoon_28: 31\n",
      "Number of frames in afternoon_29: 31\n",
      "Number of frames in afternoon_30: 31\n",
      "Number of frames in afternoon_31: 31\n",
      "Number of frames in afternoon_32: 30\n",
      "Number of frames in afternoon_33: 31\n",
      "Number of frames in afternoon_34: 31\n",
      "Number of frames in afternoon_35: 31\n",
      "Number of frames in afternoon_36: 31\n",
      "Number of frames in afternoon_37: 31\n",
      "Number of frames in afternoon_38: 31\n",
      "Number of frames in afternoon_39: 31\n",
      "Number of frames in afternoon_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/again\n",
      "Number of instances: 5\n",
      "Number of frames in again_1: 96\n",
      "Number of frames in again_2: 96\n",
      "Number of frames in again_3: 70\n",
      "Number of frames in again_4: 57\n",
      "Number of frames in again_5: 55\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/alligator\n",
      "Number of instances: 50\n",
      "Number of frames in alligator_1: 125\n",
      "Number of frames in alligator_2: 25\n",
      "Number of frames in alligator_3: 88\n",
      "Number of frames in alligator_4: 31\n",
      "Number of frames in alligator_5: 23\n",
      "Number of frames in alligator_6: 29\n",
      "Number of frames in alligator_7: 6\n",
      "Number of frames in alligator_8: 25\n",
      "Number of frames in alligator_9: 63\n",
      "Number of frames in alligator_10: 35\n",
      "Number of frames in alligator_11: 32\n",
      "Number of frames in alligator_12: 25\n",
      "Number of frames in alligator_13: 14\n",
      "Number of frames in alligator_14: 22\n",
      "Number of frames in alligator_15: 35\n",
      "Number of frames in alligator_16: 107\n",
      "Number of frames in alligator_17: 34\n",
      "Number of frames in alligator_18: 33\n",
      "Number of frames in alligator_19: 84\n",
      "Number of frames in alligator_20: 68\n",
      "Number of frames in alligator_21: 29\n",
      "Number of frames in alligator_22: 6\n",
      "Number of frames in alligator_23: 27\n",
      "Number of frames in alligator_24: 6\n",
      "Number of frames in alligator_25: 6\n",
      "Number of frames in alligator_26: 101\n",
      "Number of frames in alligator_27: 12\n",
      "Number of frames in alligator_28: 30\n",
      "Number of frames in alligator_29: 14\n",
      "Number of frames in alligator_30: 20\n",
      "Number of frames in alligator_31: 46\n",
      "Number of frames in alligator_32: 17\n",
      "Number of frames in alligator_33: 267\n",
      "Number of frames in alligator_34: 20\n",
      "Number of frames in alligator_35: 56\n",
      "Number of frames in alligator_36: 7\n",
      "Number of frames in alligator_37: 118\n",
      "Number of frames in alligator_38: 36\n",
      "Number of frames in alligator_39: 17\n",
      "Number of frames in alligator_40: 39\n",
      "Number of frames in alligator_41: 17\n",
      "Number of frames in alligator_42: 57\n",
      "Number of frames in alligator_43: 6\n",
      "Number of frames in alligator_44: 21\n",
      "Number of frames in alligator_45: 36\n",
      "Number of frames in alligator_46: 6\n",
      "Number of frames in alligator_47: 21\n",
      "Number of frames in alligator_48: 14\n",
      "Number of frames in alligator_49: 11\n",
      "Number of frames in alligator_50: 40\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/base\n",
      "Number of instances: 20\n",
      "Number of frames in base_1: 31\n",
      "Number of frames in base_2: 15\n",
      "Number of frames in base_3: 15\n",
      "Number of frames in base_4: 16\n",
      "Number of frames in base_5: 17\n",
      "Number of frames in base_6: 20\n",
      "Number of frames in base_7: 20\n",
      "Number of frames in base_8: 15\n",
      "Number of frames in base_9: 18\n",
      "Number of frames in base_10: 16\n",
      "Number of frames in base_11: 17\n",
      "Number of frames in base_12: 19\n",
      "Number of frames in base_13: 14\n",
      "Number of frames in base_14: 22\n",
      "Number of frames in base_15: 18\n",
      "Number of frames in base_16: 18\n",
      "Number of frames in base_17: 19\n",
      "Number of frames in base_18: 16\n",
      "Number of frames in base_19: 18\n",
      "Number of frames in base_20: 16\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/door\n",
      "Number of instances: 7\n",
      "Number of frames in door_1: 87\n",
      "Number of frames in door_2: 78\n",
      "Number of frames in door_3: 78\n",
      "Number of frames in door_4: 73\n",
      "Number of frames in door_5: 42\n",
      "Number of frames in door_6: 50\n",
      "Number of frames in door_7: 37\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/flower\n",
      "Number of instances: 50\n",
      "Number of frames in flower_1: 49\n",
      "Number of frames in flower_2: 24\n",
      "Number of frames in flower_3: 166\n",
      "Number of frames in flower_4: 15\n",
      "Number of frames in flower_5: 19\n",
      "Number of frames in flower_6: 18\n",
      "Number of frames in flower_7: 18\n",
      "Number of frames in flower_8: 67\n",
      "Number of frames in flower_9: 12\n",
      "Number of frames in flower_10: 17\n",
      "Number of frames in flower_11: 17\n",
      "Number of frames in flower_12: 22\n",
      "Number of frames in flower_13: 7\n",
      "Number of frames in flower_14: 40\n",
      "Number of frames in flower_15: 17\n",
      "Number of frames in flower_16: 48\n",
      "Number of frames in flower_17: 18\n",
      "Number of frames in flower_18: 24\n",
      "Number of frames in flower_19: 13\n",
      "Number of frames in flower_20: 20\n",
      "Number of frames in flower_21: 14\n",
      "Number of frames in flower_22: 76\n",
      "Number of frames in flower_23: 51\n",
      "Number of frames in flower_24: 18\n",
      "Number of frames in flower_25: 13\n",
      "Number of frames in flower_26: 39\n",
      "Number of frames in flower_27: 147\n",
      "Number of frames in flower_28: 11\n",
      "Number of frames in flower_29: 20\n",
      "Number of frames in flower_30: 22\n",
      "Number of frames in flower_31: 17\n",
      "Number of frames in flower_32: 7\n",
      "Number of frames in flower_33: 21\n",
      "Number of frames in flower_34: 53\n",
      "Number of frames in flower_35: 84\n",
      "Number of frames in flower_36: 15\n",
      "Number of frames in flower_37: 11\n",
      "Number of frames in flower_38: 20\n",
      "Number of frames in flower_39: 54\n",
      "Number of frames in flower_40: 218\n",
      "Number of frames in flower_41: 10\n",
      "Number of frames in flower_42: 159\n",
      "Number of frames in flower_43: 40\n",
      "Number of frames in flower_44: 160\n",
      "Number of frames in flower_45: 13\n",
      "Number of frames in flower_46: 51\n",
      "Number of frames in flower_47: 6\n",
      "Number of frames in flower_48: 30\n",
      "Number of frames in flower_49: 131\n",
      "Number of frames in flower_50: 141\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/hello\n",
      "Number of instances: 40\n",
      "Number of frames in hello_1: 31\n",
      "Number of frames in hello_2: 31\n",
      "Number of frames in hello_3: 31\n",
      "Number of frames in hello_4: 31\n",
      "Number of frames in hello_5: 31\n",
      "Number of frames in hello_6: 31\n",
      "Number of frames in hello_7: 30\n",
      "Number of frames in hello_8: 31\n",
      "Number of frames in hello_9: 31\n",
      "Number of frames in hello_10: 31\n",
      "Number of frames in hello_11: 31\n",
      "Number of frames in hello_12: 31\n",
      "Number of frames in hello_13: 31\n",
      "Number of frames in hello_14: 31\n",
      "Number of frames in hello_15: 31\n",
      "Number of frames in hello_16: 31\n",
      "Number of frames in hello_17: 31\n",
      "Number of frames in hello_18: 31\n",
      "Number of frames in hello_19: 29\n",
      "Number of frames in hello_20: 31\n",
      "Number of frames in hello_21: 31\n",
      "Number of frames in hello_22: 31\n",
      "Number of frames in hello_23: 31\n",
      "Number of frames in hello_24: 31\n",
      "Number of frames in hello_25: 31\n",
      "Number of frames in hello_26: 31\n",
      "Number of frames in hello_27: 31\n",
      "Number of frames in hello_28: 31\n",
      "Number of frames in hello_29: 31\n",
      "Number of frames in hello_30: 31\n",
      "Number of frames in hello_31: 31\n",
      "Number of frames in hello_32: 31\n",
      "Number of frames in hello_33: 31\n",
      "Number of frames in hello_34: 31\n",
      "Number of frames in hello_35: 31\n",
      "Number of frames in hello_36: 31\n",
      "Number of frames in hello_37: 31\n",
      "Number of frames in hello_38: 31\n",
      "Number of frames in hello_39: 31\n",
      "Number of frames in hello_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/house\n",
      "Number of instances: 4\n",
      "Number of frames in house_1: 105\n",
      "Number of frames in house_2: 57\n",
      "Number of frames in house_3: 59\n",
      "Number of frames in house_4: 67\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/how\n",
      "Number of instances: 40\n",
      "Number of frames in how_1: 30\n",
      "Number of frames in how_2: 31\n",
      "Number of frames in how_3: 31\n",
      "Number of frames in how_4: 30\n",
      "Number of frames in how_5: 31\n",
      "Number of frames in how_6: 31\n",
      "Number of frames in how_7: 31\n",
      "Number of frames in how_8: 31\n",
      "Number of frames in how_9: 31\n",
      "Number of frames in how_10: 31\n",
      "Number of frames in how_11: 31\n",
      "Number of frames in how_12: 31\n",
      "Number of frames in how_13: 31\n",
      "Number of frames in how_14: 31\n",
      "Number of frames in how_15: 31\n",
      "Number of frames in how_16: 31\n",
      "Number of frames in how_17: 31\n",
      "Number of frames in how_18: 31\n",
      "Number of frames in how_19: 31\n",
      "Number of frames in how_20: 31\n",
      "Number of frames in how_21: 31\n",
      "Number of frames in how_22: 31\n",
      "Number of frames in how_23: 31\n",
      "Number of frames in how_24: 31\n",
      "Number of frames in how_25: 31\n",
      "Number of frames in how_26: 31\n",
      "Number of frames in how_27: 31\n",
      "Number of frames in how_28: 31\n",
      "Number of frames in how_29: 31\n",
      "Number of frames in how_30: 31\n",
      "Number of frames in how_31: 31\n",
      "Number of frames in how_32: 31\n",
      "Number of frames in how_33: 31\n",
      "Number of frames in how_34: 31\n",
      "Number of frames in how_35: 31\n",
      "Number of frames in how_36: 31\n",
      "Number of frames in how_37: 31\n",
      "Number of frames in how_38: 31\n",
      "Number of frames in how_39: 31\n",
      "Number of frames in how_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/kiss\n",
      "Number of instances: 50\n",
      "Number of frames in kiss_1: 53\n",
      "Number of frames in kiss_2: 28\n",
      "Number of frames in kiss_3: 27\n",
      "Number of frames in kiss_4: 64\n",
      "Number of frames in kiss_5: 15\n",
      "Number of frames in kiss_6: 10\n",
      "Number of frames in kiss_7: 33\n",
      "Number of frames in kiss_8: 9\n",
      "Number of frames in kiss_9: 23\n",
      "Number of frames in kiss_10: 27\n",
      "Number of frames in kiss_11: 29\n",
      "Number of frames in kiss_12: 31\n",
      "Number of frames in kiss_13: 21\n",
      "Number of frames in kiss_14: 129\n",
      "Number of frames in kiss_15: 11\n",
      "Number of frames in kiss_16: 8\n",
      "Number of frames in kiss_17: 13\n",
      "Number of frames in kiss_18: 49\n",
      "Number of frames in kiss_19: 47\n",
      "Number of frames in kiss_20: 20\n",
      "Number of frames in kiss_21: 28\n",
      "Number of frames in kiss_22: 8\n",
      "Number of frames in kiss_23: 20\n",
      "Number of frames in kiss_24: 6\n",
      "Number of frames in kiss_25: 19\n",
      "Number of frames in kiss_26: 32\n",
      "Number of frames in kiss_27: 21\n",
      "Number of frames in kiss_28: 21\n",
      "Number of frames in kiss_29: 15\n",
      "Number of frames in kiss_30: 35\n",
      "Number of frames in kiss_31: 25\n",
      "Number of frames in kiss_32: 21\n",
      "Number of frames in kiss_33: 15\n",
      "Number of frames in kiss_34: 18\n",
      "Number of frames in kiss_35: 25\n",
      "Number of frames in kiss_36: 24\n",
      "Number of frames in kiss_37: 25\n",
      "Number of frames in kiss_38: 37\n",
      "Number of frames in kiss_39: 6\n",
      "Number of frames in kiss_40: 143\n",
      "Number of frames in kiss_41: 27\n",
      "Number of frames in kiss_42: 2\n",
      "Number of frames in kiss_43: 12\n",
      "Number of frames in kiss_44: 17\n",
      "Number of frames in kiss_45: 13\n",
      "Number of frames in kiss_46: 144\n",
      "Number of frames in kiss_47: 8\n",
      "Number of frames in kiss_48: 6\n",
      "Number of frames in kiss_49: 37\n",
      "Number of frames in kiss_50: 6\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/listen\n",
      "Number of instances: 50\n",
      "Number of frames in listen_1: 6\n",
      "Number of frames in listen_2: 23\n",
      "Number of frames in listen_3: 28\n",
      "Number of frames in listen_4: 68\n",
      "Number of frames in listen_5: 6\n",
      "Number of frames in listen_6: 16\n",
      "Number of frames in listen_7: 6\n",
      "Number of frames in listen_8: 6\n",
      "Number of frames in listen_9: 8\n",
      "Number of frames in listen_10: 33\n",
      "Number of frames in listen_11: 13\n",
      "Number of frames in listen_12: 23\n",
      "Number of frames in listen_13: 191\n",
      "Number of frames in listen_14: 64\n",
      "Number of frames in listen_15: 32\n",
      "Number of frames in listen_16: 24\n",
      "Number of frames in listen_17: 77\n",
      "Number of frames in listen_18: 60\n",
      "Number of frames in listen_19: 23\n",
      "Number of frames in listen_20: 20\n",
      "Number of frames in listen_21: 15\n",
      "Number of frames in listen_22: 16\n",
      "Number of frames in listen_23: 17\n",
      "Number of frames in listen_24: 19\n",
      "Number of frames in listen_25: 17\n",
      "Number of frames in listen_26: 84\n",
      "Number of frames in listen_27: 204\n",
      "Number of frames in listen_28: 31\n",
      "Number of frames in listen_29: 6\n",
      "Number of frames in listen_30: 22\n",
      "Number of frames in listen_31: 21\n",
      "Number of frames in listen_32: 9\n",
      "Number of frames in listen_33: 132\n",
      "Number of frames in listen_34: 17\n",
      "Number of frames in listen_35: 64\n",
      "Number of frames in listen_36: 148\n",
      "Number of frames in listen_37: 45\n",
      "Number of frames in listen_38: 24\n",
      "Number of frames in listen_39: 15\n",
      "Number of frames in listen_40: 9\n",
      "Number of frames in listen_41: 12\n",
      "Number of frames in listen_42: 36\n",
      "Number of frames in listen_43: 23\n",
      "Number of frames in listen_44: 7\n",
      "Number of frames in listen_45: 38\n",
      "Number of frames in listen_46: 26\n",
      "Number of frames in listen_47: 15\n",
      "Number of frames in listen_48: 20\n",
      "Number of frames in listen_49: 92\n",
      "Number of frames in listen_50: 14\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/open\n",
      "Number of instances: 4\n",
      "Number of frames in open_1: 117\n",
      "Number of frames in open_2: 96\n",
      "Number of frames in open_3: 95\n",
      "Number of frames in open_4: 103\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/orange\n",
      "Number of instances: 50\n",
      "Number of frames in orange_1: 53\n",
      "Number of frames in orange_2: 58\n",
      "Number of frames in orange_3: 12\n",
      "Number of frames in orange_4: 30\n",
      "Number of frames in orange_5: 24\n",
      "Number of frames in orange_6: 15\n",
      "Number of frames in orange_7: 154\n",
      "Number of frames in orange_8: 31\n",
      "Number of frames in orange_9: 27\n",
      "Number of frames in orange_10: 14\n",
      "Number of frames in orange_11: 52\n",
      "Number of frames in orange_12: 152\n",
      "Number of frames in orange_13: 21\n",
      "Number of frames in orange_14: 11\n",
      "Number of frames in orange_15: 27\n",
      "Number of frames in orange_16: 133\n",
      "Number of frames in orange_17: 8\n",
      "Number of frames in orange_18: 46\n",
      "Number of frames in orange_19: 10\n",
      "Number of frames in orange_20: 56\n",
      "Number of frames in orange_21: 13\n",
      "Number of frames in orange_22: 72\n",
      "Number of frames in orange_23: 54\n",
      "Number of frames in orange_24: 40\n",
      "Number of frames in orange_25: 28\n",
      "Number of frames in orange_26: 16\n",
      "Number of frames in orange_27: 23\n",
      "Number of frames in orange_28: 132\n",
      "Number of frames in orange_29: 16\n",
      "Number of frames in orange_30: 48\n",
      "Number of frames in orange_31: 10\n",
      "Number of frames in orange_32: 52\n",
      "Number of frames in orange_33: 99\n",
      "Number of frames in orange_34: 83\n",
      "Number of frames in orange_35: 28\n",
      "Number of frames in orange_36: 24\n",
      "Number of frames in orange_37: 9\n",
      "Number of frames in orange_38: 8\n",
      "Number of frames in orange_39: 53\n",
      "Number of frames in orange_40: 22\n",
      "Number of frames in orange_41: 24\n",
      "Number of frames in orange_42: 24\n",
      "Number of frames in orange_43: 44\n",
      "Number of frames in orange_44: 254\n",
      "Number of frames in orange_45: 11\n",
      "Number of frames in orange_46: 19\n",
      "Number of frames in orange_47: 17\n",
      "Number of frames in orange_48: 52\n",
      "Number of frames in orange_49: 204\n",
      "Number of frames in orange_50: 17\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/see\n",
      "Number of instances: 40\n",
      "Number of frames in see_1: 31\n",
      "Number of frames in see_2: 31\n",
      "Number of frames in see_3: 31\n",
      "Number of frames in see_4: 31\n",
      "Number of frames in see_5: 31\n",
      "Number of frames in see_6: 31\n",
      "Number of frames in see_7: 31\n",
      "Number of frames in see_8: 31\n",
      "Number of frames in see_9: 31\n",
      "Number of frames in see_10: 31\n",
      "Number of frames in see_11: 31\n",
      "Number of frames in see_12: 31\n",
      "Number of frames in see_13: 31\n",
      "Number of frames in see_14: 31\n",
      "Number of frames in see_15: 31\n",
      "Number of frames in see_16: 31\n",
      "Number of frames in see_17: 31\n",
      "Number of frames in see_18: 31\n",
      "Number of frames in see_19: 31\n",
      "Number of frames in see_20: 31\n",
      "Number of frames in see_21: 31\n",
      "Number of frames in see_22: 31\n",
      "Number of frames in see_23: 31\n",
      "Number of frames in see_24: 31\n",
      "Number of frames in see_25: 31\n",
      "Number of frames in see_26: 31\n",
      "Number of frames in see_27: 31\n",
      "Number of frames in see_28: 31\n",
      "Number of frames in see_29: 31\n",
      "Number of frames in see_30: 31\n",
      "Number of frames in see_31: 31\n",
      "Number of frames in see_32: 31\n",
      "Number of frames in see_33: 31\n",
      "Number of frames in see_34: 31\n",
      "Number of frames in see_35: 31\n",
      "Number of frames in see_36: 31\n",
      "Number of frames in see_37: 31\n",
      "Number of frames in see_38: 31\n",
      "Number of frames in see_39: 31\n",
      "Number of frames in see_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/sorry\n",
      "Number of instances: 20\n",
      "Number of frames in sorry_1: 31\n",
      "Number of frames in sorry_2: 31\n",
      "Number of frames in sorry_3: 31\n",
      "Number of frames in sorry_4: 31\n",
      "Number of frames in sorry_5: 31\n",
      "Number of frames in sorry_6: 31\n",
      "Number of frames in sorry_7: 31\n",
      "Number of frames in sorry_8: 31\n",
      "Number of frames in sorry_9: 31\n",
      "Number of frames in sorry_10: 31\n",
      "Number of frames in sorry_11: 31\n",
      "Number of frames in sorry_12: 31\n",
      "Number of frames in sorry_13: 31\n",
      "Number of frames in sorry_14: 30\n",
      "Number of frames in sorry_15: 31\n",
      "Number of frames in sorry_16: 31\n",
      "Number of frames in sorry_17: 31\n",
      "Number of frames in sorry_18: 31\n",
      "Number of frames in sorry_19: 31\n",
      "Number of frames in sorry_20: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/why\n",
      "Number of instances: 20\n",
      "Number of frames in why_1: 31\n",
      "Number of frames in why_2: 31\n",
      "Number of frames in why_3: 31\n",
      "Number of frames in why_4: 31\n",
      "Number of frames in why_5: 31\n",
      "Number of frames in why_6: 31\n",
      "Number of frames in why_7: 31\n",
      "Number of frames in why_8: 31\n",
      "Number of frames in why_9: 31\n",
      "Number of frames in why_10: 31\n",
      "Number of frames in why_11: 31\n",
      "Number of frames in why_12: 31\n",
      "Number of frames in why_13: 31\n",
      "Number of frames in why_14: 31\n",
      "Number of frames in why_15: 31\n",
      "Number of frames in why_16: 31\n",
      "Number of frames in why_17: 31\n",
      "Number of frames in why_18: 31\n",
      "Number of frames in why_19: 31\n",
      "Number of frames in why_20: 31\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences, labels = [], []  # sequence -> video, labels -> action\n",
    "for action in actions:\n",
    "    no_actions = len(os.listdir(os.path.join(c_dir, 'labels', action)))\n",
    "    print('Opening path:', os.path.join(c_dir, 'labels', action))\n",
    "    print(f'Number of instances: {no_actions}')\n",
    "    for num in range(1, no_actions + 1):\n",
    "        window = []         # window -> single frame\n",
    "        file = str(action) + \"_\" + str(num)\n",
    "        no_frames_per_action = len(os.listdir(os.path.join(c_dir, 'labels', action, file)))\n",
    "        print(f'Number of frames in {file}: {no_frames_per_action}')\n",
    "        for frame_num in range(1, no_frames_per_action + 1):\n",
    "            res = np.load(os.path.join(c_dir, 'labels', action, file,  \"{}.npy\".format(frame_num)))     # res -> coordinate key points\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "    print('-'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to difference in number of frames, pad x and y\n",
    "x = np.array(pad_sequences(sequences, dtype = 'float', padding = 'post', value = 0))\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 267, 225)\n",
      "(98, 267, 225)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.66666666666666"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2/3)*(x_train.shape[2]+y_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard, TerminateOnNaN, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logging of data with TensorBoard\n",
    "log_dir = os.path.join(c_dir, 'Logs')\n",
    "tb_callback = TensorBoard(log_dir = log_dir)\n",
    "\n",
    "# to end training when failure happens ie. loss == nan\n",
    "term = TerminateOnNaN()\n",
    "\n",
    "# to stop training early if there is no change in loss\n",
    "early = EarlyStopping(monitor = 'loss', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_lstm(n):\n",
    "    if n == 1:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, return_sequences = True, input_shape = input_shape))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Bidirectional(LSTM(64)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    elif n == 2:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, return_sequences = True, input_shape = (117, 225)))\n",
    "        model.add(LSTM(128, return_sequences = True))\n",
    "        model.add(LSTM(64, return_sequences = False))\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(32))\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    elif n == 3:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, return_sequences = True, input_shape = (117, 225)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(LSTM(64, return_sequences = False))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    elif n == 4:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, return_sequences=True, activation='relu', input_shape = input_shape))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(256, return_sequences=False, activation='relu'))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 267, 64)           74240     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 267, 64)           0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 128)               66048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142352 (556.06 KB)\n",
      "Trainable params: 142352 (556.06 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = choose_lstm(1)\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = ['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 4s 77ms/step - loss: 2.5615 - categorical_accuracy: 0.1661 - val_loss: 2.3756 - val_categorical_accuracy: 0.1772\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 2.0489 - categorical_accuracy: 0.3227 - val_loss: 2.0213 - val_categorical_accuracy: 0.2911\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 1.6795 - categorical_accuracy: 0.4505 - val_loss: 1.8264 - val_categorical_accuracy: 0.3165\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 1.5816 - categorical_accuracy: 0.4089 - val_loss: 1.7712 - val_categorical_accuracy: 0.2532\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 1.4747 - categorical_accuracy: 0.4313 - val_loss: 1.5681 - val_categorical_accuracy: 0.4177\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 1.3150 - categorical_accuracy: 0.5272 - val_loss: 1.5406 - val_categorical_accuracy: 0.4177\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 1.2981 - categorical_accuracy: 0.5144 - val_loss: 1.5168 - val_categorical_accuracy: 0.4051\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 1.3290 - categorical_accuracy: 0.4728 - val_loss: 1.4078 - val_categorical_accuracy: 0.4051\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 1.1598 - categorical_accuracy: 0.5623 - val_loss: 1.2971 - val_categorical_accuracy: 0.4937\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 1.2529 - categorical_accuracy: 0.5208 - val_loss: 1.4770 - val_categorical_accuracy: 0.3291\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 1.3630 - categorical_accuracy: 0.4633 - val_loss: 1.4432 - val_categorical_accuracy: 0.3924\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 1.2109 - categorical_accuracy: 0.5463 - val_loss: 1.2982 - val_categorical_accuracy: 0.4430\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 1.1670 - categorical_accuracy: 0.5527 - val_loss: 1.4103 - val_categorical_accuracy: 0.4051\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 1.0681 - categorical_accuracy: 0.6166 - val_loss: 1.3507 - val_categorical_accuracy: 0.4304\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 1.0783 - categorical_accuracy: 0.5911 - val_loss: 1.1733 - val_categorical_accuracy: 0.5823\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.9707 - categorical_accuracy: 0.6294 - val_loss: 1.3107 - val_categorical_accuracy: 0.4557\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 1.0849 - categorical_accuracy: 0.5527 - val_loss: 1.1853 - val_categorical_accuracy: 0.4810\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.9447 - categorical_accuracy: 0.6390 - val_loss: 1.1260 - val_categorical_accuracy: 0.5570\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.9318 - categorical_accuracy: 0.6006 - val_loss: 1.1132 - val_categorical_accuracy: 0.5443\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.8947 - categorical_accuracy: 0.6358 - val_loss: 1.0685 - val_categorical_accuracy: 0.5696\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.9100 - categorical_accuracy: 0.6262 - val_loss: 1.0705 - val_categorical_accuracy: 0.5823\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 1.2013 - categorical_accuracy: 0.5655 - val_loss: 1.1618 - val_categorical_accuracy: 0.5190\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 1.0412 - categorical_accuracy: 0.5815 - val_loss: 1.1279 - val_categorical_accuracy: 0.5696\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.9132 - categorical_accuracy: 0.6486 - val_loss: 1.0307 - val_categorical_accuracy: 0.6203\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.8173 - categorical_accuracy: 0.6901 - val_loss: 1.0405 - val_categorical_accuracy: 0.6203\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.8267 - categorical_accuracy: 0.6837 - val_loss: 1.0253 - val_categorical_accuracy: 0.5570\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.7807 - categorical_accuracy: 0.6869 - val_loss: 0.9895 - val_categorical_accuracy: 0.6203\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.7237 - categorical_accuracy: 0.7061 - val_loss: 1.0153 - val_categorical_accuracy: 0.6203\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.7659 - categorical_accuracy: 0.6997 - val_loss: 1.0119 - val_categorical_accuracy: 0.6076\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.7409 - categorical_accuracy: 0.6997 - val_loss: 1.0984 - val_categorical_accuracy: 0.5696\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.7287 - categorical_accuracy: 0.7093 - val_loss: 0.8660 - val_categorical_accuracy: 0.6962\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.6858 - categorical_accuracy: 0.7508 - val_loss: 0.9052 - val_categorical_accuracy: 0.6709\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.7243 - categorical_accuracy: 0.7125 - val_loss: 1.1490 - val_categorical_accuracy: 0.5823\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.6819 - categorical_accuracy: 0.7700 - val_loss: 1.0055 - val_categorical_accuracy: 0.6203\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.7254 - categorical_accuracy: 0.7348 - val_loss: 0.8997 - val_categorical_accuracy: 0.6962\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.6900 - categorical_accuracy: 0.7284 - val_loss: 0.9459 - val_categorical_accuracy: 0.6835\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.8740 - categorical_accuracy: 0.6677 - val_loss: 0.9236 - val_categorical_accuracy: 0.6709\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.7152 - categorical_accuracy: 0.7125 - val_loss: 0.8776 - val_categorical_accuracy: 0.7089\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.6904 - categorical_accuracy: 0.7220 - val_loss: 0.8540 - val_categorical_accuracy: 0.6329\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.6643 - categorical_accuracy: 0.7604 - val_loss: 0.8936 - val_categorical_accuracy: 0.7215\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.6032 - categorical_accuracy: 0.7668 - val_loss: 0.7538 - val_categorical_accuracy: 0.7342\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5081 - categorical_accuracy: 0.8147 - val_loss: 0.8159 - val_categorical_accuracy: 0.6962\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.5819 - categorical_accuracy: 0.7796 - val_loss: 0.9507 - val_categorical_accuracy: 0.6582\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5629 - categorical_accuracy: 0.8211 - val_loss: 0.8502 - val_categorical_accuracy: 0.7595\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5618 - categorical_accuracy: 0.7891 - val_loss: 0.7774 - val_categorical_accuracy: 0.7342\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5532 - categorical_accuracy: 0.7955 - val_loss: 0.7800 - val_categorical_accuracy: 0.7089\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.6007 - categorical_accuracy: 0.7508 - val_loss: 0.7966 - val_categorical_accuracy: 0.7089\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.5350 - categorical_accuracy: 0.8115 - val_loss: 0.7640 - val_categorical_accuracy: 0.7595\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4496 - categorical_accuracy: 0.8658 - val_loss: 0.7320 - val_categorical_accuracy: 0.7468\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4723 - categorical_accuracy: 0.8051 - val_loss: 0.6490 - val_categorical_accuracy: 0.8228\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4007 - categorical_accuracy: 0.8850 - val_loss: 0.7779 - val_categorical_accuracy: 0.7468\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4290 - categorical_accuracy: 0.8403 - val_loss: 0.7204 - val_categorical_accuracy: 0.7342\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4502 - categorical_accuracy: 0.8371 - val_loss: 0.6739 - val_categorical_accuracy: 0.7595\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5428 - categorical_accuracy: 0.8243 - val_loss: 0.8015 - val_categorical_accuracy: 0.6962\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.6096 - categorical_accuracy: 0.7668 - val_loss: 0.7352 - val_categorical_accuracy: 0.7468\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4659 - categorical_accuracy: 0.8371 - val_loss: 0.6633 - val_categorical_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4461 - categorical_accuracy: 0.8371 - val_loss: 0.8480 - val_categorical_accuracy: 0.6835\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4506 - categorical_accuracy: 0.8275 - val_loss: 0.7664 - val_categorical_accuracy: 0.7722\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.8687 - categorical_accuracy: 0.7476 - val_loss: 1.0448 - val_categorical_accuracy: 0.6709\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.6711 - categorical_accuracy: 0.7476 - val_loss: 0.9635 - val_categorical_accuracy: 0.6582\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.6473 - categorical_accuracy: 0.7540 - val_loss: 0.9842 - val_categorical_accuracy: 0.6456\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.7965 - categorical_accuracy: 0.7508 - val_loss: 1.2179 - val_categorical_accuracy: 0.5696\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5834 - categorical_accuracy: 0.8051 - val_loss: 0.8144 - val_categorical_accuracy: 0.7089\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5775 - categorical_accuracy: 0.7955 - val_loss: 0.7961 - val_categorical_accuracy: 0.7595\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5454 - categorical_accuracy: 0.7987 - val_loss: 0.7877 - val_categorical_accuracy: 0.7089\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4456 - categorical_accuracy: 0.8403 - val_loss: 0.7304 - val_categorical_accuracy: 0.7722\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3926 - categorical_accuracy: 0.8818 - val_loss: 0.7238 - val_categorical_accuracy: 0.7722\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3954 - categorical_accuracy: 0.8594 - val_loss: 0.9096 - val_categorical_accuracy: 0.6709\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.3998 - categorical_accuracy: 0.8498 - val_loss: 0.8507 - val_categorical_accuracy: 0.7595\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3779 - categorical_accuracy: 0.8722 - val_loss: 0.7437 - val_categorical_accuracy: 0.7595\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.3737 - categorical_accuracy: 0.8690 - val_loss: 0.7881 - val_categorical_accuracy: 0.7342\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4347 - categorical_accuracy: 0.8562 - val_loss: 0.7961 - val_categorical_accuracy: 0.7342\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5394 - categorical_accuracy: 0.7859 - val_loss: 0.8294 - val_categorical_accuracy: 0.7468\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4144 - categorical_accuracy: 0.8562 - val_loss: 0.8052 - val_categorical_accuracy: 0.7595\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3128 - categorical_accuracy: 0.8914 - val_loss: 0.7912 - val_categorical_accuracy: 0.7342\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2601 - categorical_accuracy: 0.9169 - val_loss: 0.7682 - val_categorical_accuracy: 0.7595\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2527 - categorical_accuracy: 0.9169 - val_loss: 0.6530 - val_categorical_accuracy: 0.7848\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.2697 - categorical_accuracy: 0.9169 - val_loss: 0.8154 - val_categorical_accuracy: 0.7342\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.2351 - categorical_accuracy: 0.9425 - val_loss: 0.6145 - val_categorical_accuracy: 0.8354\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.2231 - categorical_accuracy: 0.9425 - val_loss: 1.0502 - val_categorical_accuracy: 0.7089\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.7598 - categorical_accuracy: 0.7700 - val_loss: 1.1220 - val_categorical_accuracy: 0.6582\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.6178 - categorical_accuracy: 0.7827 - val_loss: 1.3117 - val_categorical_accuracy: 0.5949\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.7361 - categorical_accuracy: 0.7157 - val_loss: 0.9970 - val_categorical_accuracy: 0.6329\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.6026 - categorical_accuracy: 0.7923 - val_loss: 0.8971 - val_categorical_accuracy: 0.7089\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4643 - categorical_accuracy: 0.8115 - val_loss: 0.7536 - val_categorical_accuracy: 0.7342\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3590 - categorical_accuracy: 0.8722 - val_loss: 0.6692 - val_categorical_accuracy: 0.7722\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.3591 - categorical_accuracy: 0.8914 - val_loss: 0.8340 - val_categorical_accuracy: 0.6962\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4672 - categorical_accuracy: 0.8243 - val_loss: 0.5933 - val_categorical_accuracy: 0.8228\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4003 - categorical_accuracy: 0.8594 - val_loss: 0.8269 - val_categorical_accuracy: 0.6962\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.7016 - categorical_accuracy: 0.7732 - val_loss: 0.9668 - val_categorical_accuracy: 0.6709\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4471 - categorical_accuracy: 0.8339 - val_loss: 0.7310 - val_categorical_accuracy: 0.7215\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3543 - categorical_accuracy: 0.8690 - val_loss: 0.6766 - val_categorical_accuracy: 0.7848\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2751 - categorical_accuracy: 0.9073 - val_loss: 0.6997 - val_categorical_accuracy: 0.7468\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2761 - categorical_accuracy: 0.9329 - val_loss: 0.8159 - val_categorical_accuracy: 0.7595\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2459 - categorical_accuracy: 0.9329 - val_loss: 0.7710 - val_categorical_accuracy: 0.7468\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2462 - categorical_accuracy: 0.9265 - val_loss: 0.6972 - val_categorical_accuracy: 0.7975\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.2420 - categorical_accuracy: 0.9265 - val_loss: 0.7322 - val_categorical_accuracy: 0.8228\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2334 - categorical_accuracy: 0.9201 - val_loss: 0.6685 - val_categorical_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2632 - categorical_accuracy: 0.8978 - val_loss: 0.8234 - val_categorical_accuracy: 0.7722\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3621 - categorical_accuracy: 0.8594 - val_loss: 0.7089 - val_categorical_accuracy: 0.7722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f42884b4ca0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 16, validation_split = 0.2, callbacks = [term, tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f427f7bb940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# take model predictions\n",
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03312668e-04, 6.00084313e-05, 7.47255835e-05, ...,\n",
       "        9.79686081e-01, 1.18928151e-02, 8.76464648e-04],\n",
       "       [1.90223844e-04, 7.80099246e-04, 5.05305035e-03, ...,\n",
       "        4.80425078e-04, 1.12958229e-03, 8.77167471e-03],\n",
       "       [8.76470658e-05, 1.46894227e-03, 3.27843875e-02, ...,\n",
       "        4.55667236e-04, 1.49985781e-05, 7.53068423e-04],\n",
       "       ...,\n",
       "       [6.68247580e-04, 2.42819326e-04, 8.16543251e-02, ...,\n",
       "        7.84843578e-04, 1.03556877e-03, 8.46534022e-05],\n",
       "       [2.66178162e-04, 9.69008077e-04, 1.06978533e-03, ...,\n",
       "        1.40674214e-03, 7.94374355e-05, 1.61573663e-03],\n",
       "       [5.80676933e-05, 1.00301746e-04, 2.04387167e-03, ...,\n",
       "        7.10007007e-05, 1.05716765e-03, 1.59568866e-04]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis = 1).tolist()\n",
    "y_pred = np.argmax(res, axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 5, 10, 2, 9, 10, 5, 14, 6, 15, 2, 2, 9, 5, 6, 9, 10, 2, 0, 5, 10, 2, 0, 8, 9, 15, 2, 8, 14, 12, 8, 3, 10, 12, 3, 5, 8, 3, 6, 12, 9, 2, 12, 13, 13, 6, 7, 9, 14, 12, 5, 14, 2, 0, 10, 0, 15, 8, 10, 13, 12, 10, 13, 10, 13, 6, 5, 8, 2, 6, 8, 12, 9, 12, 0, 4, 11, 9, 5, 15, 13, 3, 10, 0, 12, 13, 0, 6, 8, 1, 12, 5, 9, 0, 2, 9, 6, 5]\n",
      "[13, 5, 10, 5, 9, 10, 2, 14, 6, 15, 2, 10, 9, 5, 6, 9, 9, 2, 0, 5, 10, 2, 0, 8, 9, 15, 2, 8, 14, 5, 8, 3, 10, 5, 3, 12, 8, 3, 6, 5, 15, 2, 8, 13, 13, 6, 7, 2, 14, 5, 5, 14, 2, 0, 2, 0, 15, 8, 10, 13, 12, 10, 13, 2, 13, 6, 5, 8, 2, 6, 8, 12, 5, 12, 8, 11, 7, 0, 5, 15, 13, 3, 5, 8, 2, 13, 0, 6, 8, 1, 5, 5, 9, 0, 10, 9, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round(accuracy_score(y_true, y_pred)*100, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy insufficient\n"
     ]
    }
   ],
   "source": [
    "if accuracy_score(y_true, y_pred) >= 0.8:\n",
    "    model.save('test_model_70.keras')\n",
    "else:\n",
    "    print('Model accuracy insufficient')\n",
    "\n",
    "# keras.models.load_model(\"test_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# folder_path = './averaged_np_labels/'\n",
    "# parent_files = os.listdir(os.path.join(folder_path))\n",
    "# write_path = './labels/'\n",
    "\n",
    "# for parent_file in parent_files:\n",
    "#     parent_path = os.path.join(folder_path, parent_file)\n",
    "#     export_path = os.path.join(write_path, parent_file)\n",
    "#     os.mkdir(export_path)\n",
    "#     print(f'Created new directory: {export_path}')\n",
    "#     for i in range(1, len(os.listdir(os.path.join(folder_path, parent_file)))+1):\n",
    "#         new_subfolder = f'{parent_file}_{i}'\n",
    "#         os.mkdir(os.path.join(export_path, new_subfolder))\n",
    "#         print(f'Created new subdirectory: {new_subfolder}')\n",
    "\n",
    "#         source = os.path.join(parent_path, f'video{i}')\n",
    "#         destination = os.path.join(os.path.join(export_path, new_subfolder))\n",
    "\n",
    "#         sourcefolder = os.listdir(os.path.join(parent_path, f'video{i}'))\n",
    "#         for file in sourcefolder:\n",
    "#             file_to_copy = os.path.join(os.path.join(parent_path, f'video{i}'), file)\n",
    "#             shutil.copy(file_to_copy, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is460proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
