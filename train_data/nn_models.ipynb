{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path\n",
    "directory_path = '/mnt/d/GitHub/SSLrecognition/train_data/videos'\n",
    "# current directory\n",
    "c_dir = os.getcwd()\n",
    "\n",
    "# all actions\n",
    "# actions = np.array(sorted([folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))])) # sorted to follow folder arrangement\n",
    "\n",
    "# specific actions\n",
    "# actions = np.array(['alligator', 'flower', 'kiss', 'listen', 'orange'])\n",
    "actions = np.array(['afternoon', 'house', 'again', 'open', 'kiss', 'sorry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afternoon': 0, 'house': 1, 'again': 2, 'open': 3, 'kiss': 4, 'sorry': 5}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary for int representation of actions\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at this point, we will not access the video folder, only the numpy folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening path: d:\\GitHub\\SSLrecognition\\train_data\\labels\\afternoon\n",
      "Number of instances: 40\n",
      "Number of frames in afternoon_1: 31\n",
      "Number of frames in afternoon_2: 30\n",
      "Number of frames in afternoon_3: 30\n",
      "Number of frames in afternoon_4: 30\n",
      "Number of frames in afternoon_5: 31\n",
      "Number of frames in afternoon_6: 31\n",
      "Number of frames in afternoon_7: 31\n",
      "Number of frames in afternoon_8: 30\n",
      "Number of frames in afternoon_9: 31\n",
      "Number of frames in afternoon_10: 31\n",
      "Number of frames in afternoon_11: 31\n",
      "Number of frames in afternoon_12: 31\n",
      "Number of frames in afternoon_13: 31\n",
      "Number of frames in afternoon_14: 31\n",
      "Number of frames in afternoon_15: 31\n",
      "Number of frames in afternoon_16: 31\n",
      "Number of frames in afternoon_17: 31\n",
      "Number of frames in afternoon_18: 31\n",
      "Number of frames in afternoon_19: 31\n",
      "Number of frames in afternoon_20: 31\n",
      "Number of frames in afternoon_21: 31\n",
      "Number of frames in afternoon_22: 31\n",
      "Number of frames in afternoon_23: 31\n",
      "Number of frames in afternoon_24: 31\n",
      "Number of frames in afternoon_25: 31\n",
      "Number of frames in afternoon_26: 31\n",
      "Number of frames in afternoon_27: 30\n",
      "Number of frames in afternoon_28: 31\n",
      "Number of frames in afternoon_29: 31\n",
      "Number of frames in afternoon_30: 31\n",
      "Number of frames in afternoon_31: 31\n",
      "Number of frames in afternoon_32: 30\n",
      "Number of frames in afternoon_33: 31\n",
      "Number of frames in afternoon_34: 31\n",
      "Number of frames in afternoon_35: 31\n",
      "Number of frames in afternoon_36: 31\n",
      "Number of frames in afternoon_37: 31\n",
      "Number of frames in afternoon_38: 31\n",
      "Number of frames in afternoon_39: 31\n",
      "Number of frames in afternoon_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: d:\\GitHub\\SSLrecognition\\train_data\\labels\\house\n",
      "Number of instances: 4\n",
      "Number of frames in house_1: 105\n",
      "Number of frames in house_2: 57\n",
      "Number of frames in house_3: 59\n",
      "Number of frames in house_4: 67\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: d:\\GitHub\\SSLrecognition\\train_data\\labels\\again\n",
      "Number of instances: 5\n",
      "Number of frames in again_1: 96\n",
      "Number of frames in again_2: 96\n",
      "Number of frames in again_3: 70\n",
      "Number of frames in again_4: 57\n",
      "Number of frames in again_5: 55\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: d:\\GitHub\\SSLrecognition\\train_data\\labels\\open\n",
      "Number of instances: 4\n",
      "Number of frames in open_1: 117\n",
      "Number of frames in open_2: 96\n",
      "Number of frames in open_3: 95\n",
      "Number of frames in open_4: 103\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: d:\\GitHub\\SSLrecognition\\train_data\\labels\\kiss\n",
      "Number of instances: 50\n",
      "Number of frames in kiss_1: 53\n",
      "Number of frames in kiss_2: 28\n",
      "Number of frames in kiss_3: 27\n",
      "Number of frames in kiss_4: 64\n",
      "Number of frames in kiss_5: 15\n",
      "Number of frames in kiss_6: 10\n",
      "Number of frames in kiss_7: 33\n",
      "Number of frames in kiss_8: 9\n",
      "Number of frames in kiss_9: 23\n",
      "Number of frames in kiss_10: 27\n",
      "Number of frames in kiss_11: 29\n",
      "Number of frames in kiss_12: 31\n",
      "Number of frames in kiss_13: 21\n",
      "Number of frames in kiss_14: 129\n",
      "Number of frames in kiss_15: 11\n",
      "Number of frames in kiss_16: 8\n",
      "Number of frames in kiss_17: 13\n",
      "Number of frames in kiss_18: 49\n",
      "Number of frames in kiss_19: 47\n",
      "Number of frames in kiss_20: 20\n",
      "Number of frames in kiss_21: 28\n",
      "Number of frames in kiss_22: 8\n",
      "Number of frames in kiss_23: 20\n",
      "Number of frames in kiss_24: 6\n",
      "Number of frames in kiss_25: 19\n",
      "Number of frames in kiss_26: 32\n",
      "Number of frames in kiss_27: 21\n",
      "Number of frames in kiss_28: 21\n",
      "Number of frames in kiss_29: 15\n",
      "Number of frames in kiss_30: 35\n",
      "Number of frames in kiss_31: 25\n",
      "Number of frames in kiss_32: 21\n",
      "Number of frames in kiss_33: 15\n",
      "Number of frames in kiss_34: 18\n",
      "Number of frames in kiss_35: 25\n",
      "Number of frames in kiss_36: 24\n",
      "Number of frames in kiss_37: 25\n",
      "Number of frames in kiss_38: 37\n",
      "Number of frames in kiss_39: 6\n",
      "Number of frames in kiss_40: 143\n",
      "Number of frames in kiss_41: 27\n",
      "Number of frames in kiss_42: 2\n",
      "Number of frames in kiss_43: 12\n",
      "Number of frames in kiss_44: 17\n",
      "Number of frames in kiss_45: 13\n",
      "Number of frames in kiss_46: 144\n",
      "Number of frames in kiss_47: 8\n",
      "Number of frames in kiss_48: 6\n",
      "Number of frames in kiss_49: 37\n",
      "Number of frames in kiss_50: 6\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: d:\\GitHub\\SSLrecognition\\train_data\\labels\\sorry\n",
      "Number of instances: 20\n",
      "Number of frames in sorry_1: 31\n",
      "Number of frames in sorry_2: 31\n",
      "Number of frames in sorry_3: 31\n",
      "Number of frames in sorry_4: 31\n",
      "Number of frames in sorry_5: 31\n",
      "Number of frames in sorry_6: 31\n",
      "Number of frames in sorry_7: 31\n",
      "Number of frames in sorry_8: 31\n",
      "Number of frames in sorry_9: 31\n",
      "Number of frames in sorry_10: 31\n",
      "Number of frames in sorry_11: 31\n",
      "Number of frames in sorry_12: 31\n",
      "Number of frames in sorry_13: 31\n",
      "Number of frames in sorry_14: 30\n",
      "Number of frames in sorry_15: 31\n",
      "Number of frames in sorry_16: 31\n",
      "Number of frames in sorry_17: 31\n",
      "Number of frames in sorry_18: 31\n",
      "Number of frames in sorry_19: 31\n",
      "Number of frames in sorry_20: 31\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences, labels = [], []  # sequence -> video, labels -> action\n",
    "for action in actions:\n",
    "    no_actions = len(os.listdir(os.path.join(c_dir, 'labels', action)))\n",
    "    print('Opening path:', os.path.join(c_dir, 'labels', action))\n",
    "    print(f'Number of instances: {no_actions}')\n",
    "    for num in range(1, no_actions + 1):\n",
    "        window = []         # window -> single frame\n",
    "        file = str(action) + \"_\" + str(num)\n",
    "        no_frames_per_action = len(os.listdir(os.path.join(c_dir, 'labels', action, file)))\n",
    "        print(f'Number of frames in {file}: {no_frames_per_action}')\n",
    "        for frame_num in range(1, no_frames_per_action + 1):\n",
    "            res = np.load(os.path.join(c_dir, 'labels', action, file,  \"{}.npy\".format(frame_num)))     # res -> coordinate key points\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "    print('-'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to difference in number of frames, pad x and y\n",
    "x = np.array(pad_sequences(sequences, dtype = 'float', padding = 'post', value = 0))\n",
    "y = pad_sequences(to_categorical(labels).astype(int), dtype = 'int', padding = 'post', value = -1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[1], x_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard, TerminateOnNaN, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logging of data with TensorBoard\n",
    "# log_dir = os.path.join(c_dir, 'Logs')\n",
    "# tb_callback = TensorBoard(log_dir = log_dir)\n",
    "\n",
    "# to end training when failure happens ie. loss == nan\n",
    "term = TerminateOnNaN()\n",
    "\n",
    "# to stop training early if there is no change in loss\n",
    "early = EarlyStopping(monitor = 'loss', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_lstm(n):\n",
    "    if n == 1:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(256, return_sequences = True, input_shape = input_shape))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Bidirectional(LSTM(512, return_sequences = True)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Bidirectional(LSTM(512)))\n",
    "        model.add(Dropout(0.2))\n",
    "        # model.add(LSTM(512, return_sequences = False))\n",
    "        # model.add(Dropout(0.2))\n",
    "        # model.add(Dense(512, activation='relu'))\n",
    "        # model.add(Dense(256, activation='relu'))\n",
    "        # model.add(Dense(128, activation='relu'))\n",
    "        # model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    elif n == 2:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, return_sequences = True, input_shape = (117, 225)))\n",
    "        model.add(LSTM(128, return_sequences = True))\n",
    "        model.add(LSTM(64, return_sequences = False))\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(32))\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    elif n == 3:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, return_sequences = True, input_shape = (117, 225)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(LSTM(64, return_sequences = False))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    elif n == 4:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, return_sequences=True, activation='relu', input_shape = input_shape))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(256, return_sequences=False, activation='relu'))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_60 (LSTM)              (None, 144, 256)          493568    \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 144, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirecti  (None, 144, 1024)         3149824   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 144, 1024)         0         \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirecti  (None, 1024)              6295552   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9945094 (37.94 MB)\n",
      "Trainable params: 9945094 (37.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = choose_lstm(1)\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = ['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 81s 3s/step - loss: 1.1825 - categorical_accuracy: 0.5636\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 77s 3s/step - loss: 0.6162 - categorical_accuracy: 0.7909\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.6967 - categorical_accuracy: 0.8091\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.6392 - categorical_accuracy: 0.7364\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.5298 - categorical_accuracy: 0.8455\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.7009 - categorical_accuracy: 0.7636\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.5736 - categorical_accuracy: 0.8091\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 77s 3s/step - loss: 0.2541 - categorical_accuracy: 0.8909\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 79s 3s/step - loss: 0.3491 - categorical_accuracy: 0.8636\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.1844 - categorical_accuracy: 0.9091\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.1817 - categorical_accuracy: 0.9182\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 79s 3s/step - loss: 0.1100 - categorical_accuracy: 0.9364\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.1006 - categorical_accuracy: 0.9455\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.1212 - categorical_accuracy: 0.9455\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.3467 - categorical_accuracy: 0.8818\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 77s 3s/step - loss: 0.3178 - categorical_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 78s 3s/step - loss: 0.2596 - categorical_accuracy: 0.9182\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.7947 - categorical_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a85c430e80>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 4, callbacks = [term, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# take model predictions\n",
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.60599828e-01, 1.21929878e-02, 2.41499841e-02, 4.44575772e-02,\n",
       "        3.30894045e-03, 2.55290598e-01],\n",
       "       [4.91522908e-01, 1.67969652e-02, 3.31978947e-02, 6.17153011e-02,\n",
       "        2.33108178e-01, 1.63658768e-01],\n",
       "       [7.50277102e-01, 2.00800262e-02, 3.83127294e-02, 8.39459300e-02,\n",
       "        5.08875400e-03, 1.02295458e-01],\n",
       "       [7.46304810e-01, 2.05135308e-02, 3.71590406e-02, 8.04858580e-02,\n",
       "        4.41688811e-03, 1.11119851e-01],\n",
       "       [5.00993757e-03, 9.26144829e-04, 6.75680407e-04, 1.30357919e-03,\n",
       "        9.90443408e-01, 1.64129760e-03],\n",
       "       [7.51555026e-01, 1.96979158e-02, 3.70875821e-02, 8.11098143e-02,\n",
       "        4.85402113e-03, 1.05695657e-01],\n",
       "       [2.62110263e-01, 1.24672912e-02, 2.26028152e-02, 3.91980261e-02,\n",
       "        5.68967342e-01, 9.46542323e-02],\n",
       "       [7.35668778e-01, 2.11492106e-02, 3.82543318e-02, 7.97483996e-02,\n",
       "        3.90369934e-03, 1.21275514e-01],\n",
       "       [5.45403047e-04, 2.02737298e-04, 1.27215913e-04, 2.46489362e-04,\n",
       "        9.98805404e-01, 7.27216175e-05],\n",
       "       [7.48779058e-01, 2.09627487e-02, 3.81664485e-02, 8.39560777e-02,\n",
       "        4.58912691e-03, 1.03546470e-01],\n",
       "       [6.62809014e-01, 1.20125525e-02, 2.35287454e-02, 4.36556004e-02,\n",
       "        3.24418722e-03, 2.54749954e-01],\n",
       "       [2.70046090e-04, 1.20683086e-04, 6.90279994e-05, 1.39484284e-04,\n",
       "        9.99341309e-01, 5.95029633e-05],\n",
       "       [6.51748478e-01, 1.18384380e-02, 2.31127199e-02, 4.22067940e-02,\n",
       "        3.02312011e-03, 2.68070430e-01]], dtype=float32)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis = 1).tolist()\n",
    "y_pred = np.argmax(res, axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 2, 0, 4, 1, 4, 0, 4, 0, 5, 4, 5]\n",
      "[0, 0, 0, 0, 4, 0, 4, 0, 4, 0, 0, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round(accuracy_score(y_true, y_pred)*100, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# folder_path = './averaged_np_labels/'\n",
    "# parent_files = os.listdir(os.path.join(folder_path))\n",
    "# write_path = './labels/'\n",
    "\n",
    "# for parent_file in parent_files:\n",
    "#     parent_path = os.path.join(folder_path, parent_file)\n",
    "#     export_path = os.path.join(write_path, parent_file)\n",
    "#     os.mkdir(export_path)\n",
    "#     print(f'Created new directory: {export_path}')\n",
    "#     for i in range(1, len(os.listdir(os.path.join(folder_path, parent_file)))+1):\n",
    "#         new_subfolder = f'{parent_file}_{i}'\n",
    "#         os.mkdir(os.path.join(export_path, new_subfolder))\n",
    "#         print(f'Created new subdirectory: {new_subfolder}')\n",
    "\n",
    "#         source = os.path.join(parent_path, f'video{i}')\n",
    "#         destination = os.path.join(os.path.join(export_path, new_subfolder))\n",
    "\n",
    "#         sourcefolder = os.listdir(os.path.join(parent_path, f'video{i}'))\n",
    "#         for file in sourcefolder:\n",
    "#             file_to_copy = os.path.join(os.path.join(parent_path, f'video{i}'), file)\n",
    "#             shutil.copy(file_to_copy, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is460proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
