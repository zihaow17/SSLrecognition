{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path\n",
    "directory_path = '/mnt/d/GitHub/SSLrecognition/train_data/videos'\n",
    "# current directory\n",
    "c_dir = os.getcwd()\n",
    "\n",
    "# all actions\n",
    "actions = np.array(sorted([folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))])) # sorted to follow folder arrangement\n",
    "\n",
    "# specific actions\n",
    "# actions = np.array(['base', 'again', 'how', 'open', 'sorry', 'see'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afternoon': 0,\n",
       " 'again': 1,\n",
       " 'base': 2,\n",
       " 'door': 3,\n",
       " 'hello': 4,\n",
       " 'house': 5,\n",
       " 'how': 6,\n",
       " 'open': 7,\n",
       " 'see': 8,\n",
       " 'sorry': 9,\n",
       " 'why': 10}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary for int representation of actions\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at this point, we will not access the video folder, only the numpy folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/afternoon\n",
      "Number of instances: 40\n",
      "Number of frames in afternoon_1: 31\n",
      "Number of frames in afternoon_2: 30\n",
      "Number of frames in afternoon_3: 30\n",
      "Number of frames in afternoon_4: 30\n",
      "Number of frames in afternoon_5: 31\n",
      "Number of frames in afternoon_6: 31\n",
      "Number of frames in afternoon_7: 31\n",
      "Number of frames in afternoon_8: 30\n",
      "Number of frames in afternoon_9: 31\n",
      "Number of frames in afternoon_10: 31\n",
      "Number of frames in afternoon_11: 31\n",
      "Number of frames in afternoon_12: 31\n",
      "Number of frames in afternoon_13: 31\n",
      "Number of frames in afternoon_14: 31\n",
      "Number of frames in afternoon_15: 31\n",
      "Number of frames in afternoon_16: 31\n",
      "Number of frames in afternoon_17: 31\n",
      "Number of frames in afternoon_18: 31\n",
      "Number of frames in afternoon_19: 31\n",
      "Number of frames in afternoon_20: 31\n",
      "Number of frames in afternoon_21: 31\n",
      "Number of frames in afternoon_22: 31\n",
      "Number of frames in afternoon_23: 31\n",
      "Number of frames in afternoon_24: 31\n",
      "Number of frames in afternoon_25: 31\n",
      "Number of frames in afternoon_26: 31\n",
      "Number of frames in afternoon_27: 30\n",
      "Number of frames in afternoon_28: 31\n",
      "Number of frames in afternoon_29: 31\n",
      "Number of frames in afternoon_30: 31\n",
      "Number of frames in afternoon_31: 31\n",
      "Number of frames in afternoon_32: 30\n",
      "Number of frames in afternoon_33: 31\n",
      "Number of frames in afternoon_34: 31\n",
      "Number of frames in afternoon_35: 31\n",
      "Number of frames in afternoon_36: 31\n",
      "Number of frames in afternoon_37: 31\n",
      "Number of frames in afternoon_38: 31\n",
      "Number of frames in afternoon_39: 31\n",
      "Number of frames in afternoon_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/again\n",
      "Number of instances: 5\n",
      "Number of frames in again_1: 96\n",
      "Number of frames in again_2: 96\n",
      "Number of frames in again_3: 70\n",
      "Number of frames in again_4: 57\n",
      "Number of frames in again_5: 55\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/base\n",
      "Number of instances: 20\n",
      "Number of frames in base_1: 31\n",
      "Number of frames in base_2: 15\n",
      "Number of frames in base_3: 15\n",
      "Number of frames in base_4: 16\n",
      "Number of frames in base_5: 17\n",
      "Number of frames in base_6: 20\n",
      "Number of frames in base_7: 20\n",
      "Number of frames in base_8: 15\n",
      "Number of frames in base_9: 18\n",
      "Number of frames in base_10: 16\n",
      "Number of frames in base_11: 17\n",
      "Number of frames in base_12: 19\n",
      "Number of frames in base_13: 14\n",
      "Number of frames in base_14: 22\n",
      "Number of frames in base_15: 18\n",
      "Number of frames in base_16: 18\n",
      "Number of frames in base_17: 19\n",
      "Number of frames in base_18: 16\n",
      "Number of frames in base_19: 18\n",
      "Number of frames in base_20: 16\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/door\n",
      "Number of instances: 7\n",
      "Number of frames in door_1: 87\n",
      "Number of frames in door_2: 78\n",
      "Number of frames in door_3: 78\n",
      "Number of frames in door_4: 73\n",
      "Number of frames in door_5: 42\n",
      "Number of frames in door_6: 50\n",
      "Number of frames in door_7: 37\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/hello\n",
      "Number of instances: 40\n",
      "Number of frames in hello_1: 31\n",
      "Number of frames in hello_2: 31\n",
      "Number of frames in hello_3: 31\n",
      "Number of frames in hello_4: 31\n",
      "Number of frames in hello_5: 31\n",
      "Number of frames in hello_6: 31\n",
      "Number of frames in hello_7: 30\n",
      "Number of frames in hello_8: 31\n",
      "Number of frames in hello_9: 31\n",
      "Number of frames in hello_10: 31\n",
      "Number of frames in hello_11: 31\n",
      "Number of frames in hello_12: 31\n",
      "Number of frames in hello_13: 31\n",
      "Number of frames in hello_14: 31\n",
      "Number of frames in hello_15: 31\n",
      "Number of frames in hello_16: 31\n",
      "Number of frames in hello_17: 31\n",
      "Number of frames in hello_18: 31\n",
      "Number of frames in hello_19: 29\n",
      "Number of frames in hello_20: 31\n",
      "Number of frames in hello_21: 31\n",
      "Number of frames in hello_22: 31\n",
      "Number of frames in hello_23: 31\n",
      "Number of frames in hello_24: 31\n",
      "Number of frames in hello_25: 31\n",
      "Number of frames in hello_26: 31\n",
      "Number of frames in hello_27: 31\n",
      "Number of frames in hello_28: 31\n",
      "Number of frames in hello_29: 31\n",
      "Number of frames in hello_30: 31\n",
      "Number of frames in hello_31: 31\n",
      "Number of frames in hello_32: 31\n",
      "Number of frames in hello_33: 31\n",
      "Number of frames in hello_34: 31\n",
      "Number of frames in hello_35: 31\n",
      "Number of frames in hello_36: 31\n",
      "Number of frames in hello_37: 31\n",
      "Number of frames in hello_38: 31\n",
      "Number of frames in hello_39: 31\n",
      "Number of frames in hello_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/house\n",
      "Number of instances: 4\n",
      "Number of frames in house_1: 105\n",
      "Number of frames in house_2: 57\n",
      "Number of frames in house_3: 59\n",
      "Number of frames in house_4: 67\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/how\n",
      "Number of instances: 40\n",
      "Number of frames in how_1: 30\n",
      "Number of frames in how_2: 31\n",
      "Number of frames in how_3: 31\n",
      "Number of frames in how_4: 30\n",
      "Number of frames in how_5: 31\n",
      "Number of frames in how_6: 31\n",
      "Number of frames in how_7: 31\n",
      "Number of frames in how_8: 31\n",
      "Number of frames in how_9: 31\n",
      "Number of frames in how_10: 31\n",
      "Number of frames in how_11: 31\n",
      "Number of frames in how_12: 31\n",
      "Number of frames in how_13: 31\n",
      "Number of frames in how_14: 31\n",
      "Number of frames in how_15: 31\n",
      "Number of frames in how_16: 31\n",
      "Number of frames in how_17: 31\n",
      "Number of frames in how_18: 31\n",
      "Number of frames in how_19: 31\n",
      "Number of frames in how_20: 31\n",
      "Number of frames in how_21: 31\n",
      "Number of frames in how_22: 31\n",
      "Number of frames in how_23: 31\n",
      "Number of frames in how_24: 31\n",
      "Number of frames in how_25: 31\n",
      "Number of frames in how_26: 31\n",
      "Number of frames in how_27: 31\n",
      "Number of frames in how_28: 31\n",
      "Number of frames in how_29: 31\n",
      "Number of frames in how_30: 31\n",
      "Number of frames in how_31: 31\n",
      "Number of frames in how_32: 31\n",
      "Number of frames in how_33: 31\n",
      "Number of frames in how_34: 31\n",
      "Number of frames in how_35: 31\n",
      "Number of frames in how_36: 31\n",
      "Number of frames in how_37: 31\n",
      "Number of frames in how_38: 31\n",
      "Number of frames in how_39: 31\n",
      "Number of frames in how_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/open\n",
      "Number of instances: 4\n",
      "Number of frames in open_1: 117\n",
      "Number of frames in open_2: 96\n",
      "Number of frames in open_3: 95\n",
      "Number of frames in open_4: 103\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/see\n",
      "Number of instances: 40\n",
      "Number of frames in see_1: 31\n",
      "Number of frames in see_2: 31\n",
      "Number of frames in see_3: 31\n",
      "Number of frames in see_4: 31\n",
      "Number of frames in see_5: 31\n",
      "Number of frames in see_6: 31\n",
      "Number of frames in see_7: 31\n",
      "Number of frames in see_8: 31\n",
      "Number of frames in see_9: 31\n",
      "Number of frames in see_10: 31\n",
      "Number of frames in see_11: 31\n",
      "Number of frames in see_12: 31\n",
      "Number of frames in see_13: 31\n",
      "Number of frames in see_14: 31\n",
      "Number of frames in see_15: 31\n",
      "Number of frames in see_16: 31\n",
      "Number of frames in see_17: 31\n",
      "Number of frames in see_18: 31\n",
      "Number of frames in see_19: 31\n",
      "Number of frames in see_20: 31\n",
      "Number of frames in see_21: 31\n",
      "Number of frames in see_22: 31\n",
      "Number of frames in see_23: 31\n",
      "Number of frames in see_24: 31\n",
      "Number of frames in see_25: 31\n",
      "Number of frames in see_26: 31\n",
      "Number of frames in see_27: 31\n",
      "Number of frames in see_28: 31\n",
      "Number of frames in see_29: 31\n",
      "Number of frames in see_30: 31\n",
      "Number of frames in see_31: 31\n",
      "Number of frames in see_32: 31\n",
      "Number of frames in see_33: 31\n",
      "Number of frames in see_34: 31\n",
      "Number of frames in see_35: 31\n",
      "Number of frames in see_36: 31\n",
      "Number of frames in see_37: 31\n",
      "Number of frames in see_38: 31\n",
      "Number of frames in see_39: 31\n",
      "Number of frames in see_40: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/sorry\n",
      "Number of instances: 20\n",
      "Number of frames in sorry_1: 31\n",
      "Number of frames in sorry_2: 31\n",
      "Number of frames in sorry_3: 31\n",
      "Number of frames in sorry_4: 31\n",
      "Number of frames in sorry_5: 31\n",
      "Number of frames in sorry_6: 31\n",
      "Number of frames in sorry_7: 31\n",
      "Number of frames in sorry_8: 31\n",
      "Number of frames in sorry_9: 31\n",
      "Number of frames in sorry_10: 31\n",
      "Number of frames in sorry_11: 31\n",
      "Number of frames in sorry_12: 31\n",
      "Number of frames in sorry_13: 31\n",
      "Number of frames in sorry_14: 30\n",
      "Number of frames in sorry_15: 31\n",
      "Number of frames in sorry_16: 31\n",
      "Number of frames in sorry_17: 31\n",
      "Number of frames in sorry_18: 31\n",
      "Number of frames in sorry_19: 31\n",
      "Number of frames in sorry_20: 31\n",
      "---------------------------------------------------------------------------\n",
      "Opening path: /mnt/d/GitHub/SSLrecognition/train_data/labels/why\n",
      "Number of instances: 20\n",
      "Number of frames in why_1: 31\n",
      "Number of frames in why_2: 31\n",
      "Number of frames in why_3: 31\n",
      "Number of frames in why_4: 31\n",
      "Number of frames in why_5: 31\n",
      "Number of frames in why_6: 31\n",
      "Number of frames in why_7: 31\n",
      "Number of frames in why_8: 31\n",
      "Number of frames in why_9: 31\n",
      "Number of frames in why_10: 31\n",
      "Number of frames in why_11: 31\n",
      "Number of frames in why_12: 31\n",
      "Number of frames in why_13: 31\n",
      "Number of frames in why_14: 31\n",
      "Number of frames in why_15: 31\n",
      "Number of frames in why_16: 31\n",
      "Number of frames in why_17: 31\n",
      "Number of frames in why_18: 31\n",
      "Number of frames in why_19: 31\n",
      "Number of frames in why_20: 31\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences, labels = [], []  # sequence -> video, labels -> action\n",
    "for action in actions:\n",
    "    no_actions = len(os.listdir(os.path.join(c_dir, 'labels', action)))\n",
    "    print('Opening path:', os.path.join(c_dir, 'labels', action))\n",
    "    print(f'Number of instances: {no_actions}')\n",
    "    for num in range(1, no_actions + 1):\n",
    "        window = []         # window -> single frame\n",
    "        file = str(action) + \"_\" + str(num)\n",
    "        no_frames_per_action = len(os.listdir(os.path.join(c_dir, 'labels', action, file)))\n",
    "        print(f'Number of frames in {file}: {no_frames_per_action}')\n",
    "        for frame_num in range(1, no_frames_per_action + 1):\n",
    "            res = np.load(os.path.join(c_dir, 'labels', action, file,  \"{}.npy\".format(frame_num)))     # res -> coordinate key points\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "    print('-'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to difference in number of frames, pad x and y\n",
    "x = np.array(pad_sequences(sequences, dtype = 'float', padding = 'post', value = 0))\n",
    "y = pad_sequences(to_categorical(labels).astype(int), dtype = 'int', padding = 'post', value = -1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 117, 225)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, TerminateOnNaN, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logging of data with TensorBoard\n",
    "# log_dir = os.path.join(c_dir, 'Logs')\n",
    "# tb_callback = TensorBoard(log_dir = log_dir)\n",
    "\n",
    "# to end training when failure happens ie. loss == nan\n",
    "term = TerminateOnNaN()\n",
    "\n",
    "# to stop training early if there is no change in loss\n",
    "early = EarlyStopping(monitor = 'loss', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_lstm(n):\n",
    "    if n == 1:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, return_sequences = True, input_shape = (117, 225)))\n",
    "        model.add(LSTM(64, activation = 'sigmoid'))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    elif n == 2:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, return_sequences = True, activation = \"relu\", input_shape = (117, 225)))\n",
    "        model.add(LSTM(128, return_sequences = True, activation = \"relu\"))\n",
    "        model.add(LSTM(64, return_sequences = False, activation = \"relu\"))\n",
    "        model.add(Dense(64, activation = \"relu\"))\n",
    "        model.add(Dense(32, activation = \"relu\"))\n",
    "        model.add(Dense(8, activation = \"relu\"))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    elif n == 3:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, return_sequences = True, activation = \"sigmoid\", input_shape = (117, 225)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(LSTM(64, return_sequences = False, activation = \"sigmoid\"))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(actions.shape[0], activation = \"softmax\"))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_71 (LSTM)              (None, 117, 64)           74240     \n",
      "                                                                 \n",
      " lstm_72 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107979 (421.79 KB)\n",
      "Trainable params: 107979 (421.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = choose_lstm(1)\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = ['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "7/7 [==============================] - 4s 267ms/step - loss: 2.3558 - categorical_accuracy: 0.1237 - val_loss: 2.1412 - val_categorical_accuracy: 0.1818\n",
      "Epoch 2/2000\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 2.2540 - categorical_accuracy: 0.1495 - val_loss: 2.1755 - val_categorical_accuracy: 0.3182\n",
      "Epoch 3/2000\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 2.1936 - categorical_accuracy: 0.1753 - val_loss: 2.1849 - val_categorical_accuracy: 0.1364\n",
      "Epoch 4/2000\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 2.1531 - categorical_accuracy: 0.1495 - val_loss: 2.1157 - val_categorical_accuracy: 0.3182\n",
      "Epoch 5/2000\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 2.0698 - categorical_accuracy: 0.1495 - val_loss: 2.1656 - val_categorical_accuracy: 0.1818\n",
      "Epoch 6/2000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 2.0278 - categorical_accuracy: 0.1701 - val_loss: 2.2306 - val_categorical_accuracy: 0.1364\n",
      "Epoch 7/2000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 2.0116 - categorical_accuracy: 0.1495 - val_loss: 2.1007 - val_categorical_accuracy: 0.3182\n",
      "Epoch 8/2000\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 1.9809 - categorical_accuracy: 0.1907 - val_loss: 2.0036 - val_categorical_accuracy: 0.3182\n",
      "Epoch 9/2000\n",
      "7/7 [==============================] - 1s 215ms/step - loss: 2.0338 - categorical_accuracy: 0.1753 - val_loss: 1.9311 - val_categorical_accuracy: 0.3182\n",
      "Epoch 10/2000\n",
      "7/7 [==============================] - 2s 267ms/step - loss: 1.9756 - categorical_accuracy: 0.1753 - val_loss: 2.0967 - val_categorical_accuracy: 0.1364\n",
      "Epoch 11/2000\n",
      "7/7 [==============================] - 2s 219ms/step - loss: 2.0968 - categorical_accuracy: 0.1392 - val_loss: 2.1343 - val_categorical_accuracy: 0.1364\n",
      "Epoch 12/2000\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 2.0515 - categorical_accuracy: 0.1907 - val_loss: 2.1023 - val_categorical_accuracy: 0.1364\n",
      "Epoch 13/2000\n",
      "7/7 [==============================] - 1s 201ms/step - loss: 2.0413 - categorical_accuracy: 0.1546 - val_loss: 2.1021 - val_categorical_accuracy: 0.1818\n",
      "Epoch 14/2000\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 1.9736 - categorical_accuracy: 0.1649 - val_loss: 2.0375 - val_categorical_accuracy: 0.1364\n",
      "Epoch 15/2000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 1.9257 - categorical_accuracy: 0.1804 - val_loss: 2.0914 - val_categorical_accuracy: 0.1364\n",
      "Epoch 16/2000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 1.9229 - categorical_accuracy: 0.2010 - val_loss: 2.0056 - val_categorical_accuracy: 0.1364\n",
      "Epoch 17/2000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 1.8867 - categorical_accuracy: 0.1907 - val_loss: 1.9296 - val_categorical_accuracy: 0.1364\n",
      "Epoch 18/2000\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 1.8499 - categorical_accuracy: 0.2062 - val_loss: 1.8811 - val_categorical_accuracy: 0.3636\n",
      "Epoch 19/2000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 1.7755 - categorical_accuracy: 0.2526 - val_loss: 1.7411 - val_categorical_accuracy: 0.1818\n",
      "Epoch 20/2000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 1.7207 - categorical_accuracy: 0.2526 - val_loss: 1.6948 - val_categorical_accuracy: 0.1818\n",
      "Epoch 21/2000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 1.8879 - categorical_accuracy: 0.2371 - val_loss: 1.8804 - val_categorical_accuracy: 0.1818\n",
      "Epoch 22/2000\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 1.8839 - categorical_accuracy: 0.2268 - val_loss: 2.1044 - val_categorical_accuracy: 0.1818\n",
      "Epoch 23/2000\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 1.8768 - categorical_accuracy: 0.2216 - val_loss: 2.0169 - val_categorical_accuracy: 0.2273\n",
      "Epoch 24/2000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 1.8334 - categorical_accuracy: 0.2577 - val_loss: 1.9003 - val_categorical_accuracy: 0.2273\n",
      "Epoch 25/2000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 1.7611 - categorical_accuracy: 0.2732 - val_loss: 1.8267 - val_categorical_accuracy: 0.1818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1e9432eb50>"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 2000, validation_split = 0.1, callbacks = [term, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 304ms/step\n"
     ]
    }
   ],
   "source": [
    "# take model predictions\n",
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis = 1).tolist()\n",
    "y_pred = np.argmax(res, axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round(accuracy_score(y_true, y_pred)*100, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# folder_path = './averaged_np_labels/'\n",
    "# parent_files = os.listdir(os.path.join(folder_path))\n",
    "# write_path = './labels/'\n",
    "\n",
    "# for parent_file in parent_files:\n",
    "#     parent_path = os.path.join(folder_path, parent_file)\n",
    "#     export_path = os.path.join(write_path, parent_file)\n",
    "#     os.mkdir(export_path)\n",
    "#     print(f'Created new directory: {export_path}')\n",
    "#     for i in range(1, len(os.listdir(os.path.join(folder_path, parent_file)))+1):\n",
    "#         new_subfolder = f'{parent_file}_{i}'\n",
    "#         os.mkdir(os.path.join(export_path, new_subfolder))\n",
    "#         print(f'Created new subdirectory: {new_subfolder}')\n",
    "\n",
    "#         source = os.path.join(parent_path, f'video{i}')\n",
    "#         destination = os.path.join(os.path.join(export_path, new_subfolder))\n",
    "\n",
    "#         sourcefolder = os.listdir(os.path.join(parent_path, f'video{i}'))\n",
    "#         for file in sourcefolder:\n",
    "#             file_to_copy = os.path.join(os.path.join(parent_path, f'video{i}'), file)\n",
    "#             shutil.copy(file_to_copy, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is460proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
